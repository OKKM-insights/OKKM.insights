\documentclass[12pt, titlepage]{article}

\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Verification and Validation Report: \progname} 
\author{\authname}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms -- you can reference the SRS tables if needed}

\newpage

\tableofcontents

\listoftables %if appropriate

\listoffigures %if appropriate

\newpage

\pagenumbering{arabic}

This document ...

\section{Functional Requirements Evaluation}

\section{Nonfunctional Requirements Evaluation}
\subsection{Look and Feel}
\subsubsection{Summary of Tests}
\begin{center}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{Test ID} & \textbf{Status} & \textbf{Notes}\\
        \hline
        T-LF0 & Pass & \\
        T-LF1 & Pass & \\
        T-LF2 & Pass & \\
        \hline
    \end{tabular}
\end{center}
    
\begin{enumerate}
    \item{T-LF0: Responsive Layout Validation\\}
        
    \textbf{Initial State}: Users access the application on devices with screen resolutions ranging from 1024$\times$768 pixels to 1920$\times$1080 pixels.
    
    \textbf{Input/Condition}: The application is displayed on various screen sizes within the specified range to verify adaptability and layout consistency.

    \textbf{Expected Result}: All elements are displayed on the screen, regardless of dimensions.

    \textbf{Result} Pass

    \item{T-LF1: Interactive Elements Feedback Validation\\}
    
    \textbf{Initial State}: Interactive elements (e.g., buttons, links) are present within the application interface.
    
    \textbf{Input/Condition}: Users interact with various interactive elements to verify that visual feedback is provided appropriately.
    
    \textbf{Expected Result}: Each interactive element provides feedback when hovered over and clicked on.

    \textbf{Result} Pass
    
    \item{T-LF2: Unified Visual Design Validation\\}
    
    
    \textbf{Initial State}: The application interface displays all components (buttons, menus, text fields, images, etc.) with the unified visual design specifications.
    
    \textbf{Input/Condition}: Users or testers navigate through the application to assess the consistency of font type, sizing, color, and background tones across all components.
    
    \textbf{Expected Result}: All elements follow consistent style

    \textbf{Result} Pass

    \textbf{Comments} Replacing Label Studio with our own framework was necessary to pass this test.
    
    \end{enumerate}

    \subsubsection{Analysis}
    All three of the Look and Feel tests pass. These tests were designed to provide complete coverage of the Look and Feel requirements, and therefore we believe them to be covered.
\subsection{Usability}
	Please see usability report, found \href{https://github.com/OKKM-insights/OKKM.insights/blob/main/docs/Extras/UsabilityReport/UsabilityReport.pdf}{here}

\subsection{Performance}
\subsection{Operational and Environmental}
\subsubsection{Summary of Tests}
\begin{center}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{Test ID} & \textbf{Status} & \textbf{Notes}\\
        \hline
        T-OE0 & N/A & Requirement is out of scope\\
        T-OE1 & Fail & Not yet implemented\\
        T-OE2 & N/A & Requirement is out of scope \\
        T-OE3 & N/A & Requirement is out of scope \\
        T-OE4 & Fail & Not yet implemented \\
        T-OE5 & Fail & Not yet implemented \\
        T-OE6 & Pass & \\
        T-OE7 & Pass & \\
        T-OE8 & Pass & \\
        T-OE9 & Pass & \\
        \hline
    \end{tabular}
\end{center}
\begin{enumerate}

    \item{T-OE0: Energy Efficiency Validation\\}
    
    
    \textbf{Initial State}: The system is running on cloud infrastructure with existing server management configurations.
    
    \textbf{Input/Condition}: Implement energy-efficient practices in cloud usage and server management, then measure energy consumption before and after optimization.
    
    \textbf{Expected Result}: A statistically significant decrease in energy usage with 5\% sensitivity.

    \textbf{Result}: Test not completed

    \textbf{Comments}: Requirement is out of scope
    
    
    \item{T-OE1: API and Data Format Integration Validation\\}
    
    
    \textbf{Initial State}: The system is configured with API access credentials for at least two major satellite data providers.
    
    \textbf{Input/Condition}: The system attempts to automatically acquire and integrate satellite images from the specified providers using their standardized APIs and data formats.
    
    \textbf{Expected Result}: System obtains result from API provider.

    \textbf{Result}: Fail

    \textbf{Comments}: Not yet implemented
    
    
    \item{T-OE2: Payment Processor Integration Validation\\}
    
    
    \textbf{Initial State}: The system is configured with API access credentials for reliable and secure payment processors (e.g., Stripe, PayPal).
    
    \textbf{Input/Condition}: Users and clients perform financial transactions through the integrated payment gateways.
    
    \textbf{Expected Result}: System successfully processes payment

    \textbf{Result}: Test not completed

    \textbf{Comments}: Requirement is out of scope
    
    \item{T-OE3: Multiple Currency Support Validation\\}
    
    
    \textbf{Initial State}: The system is configured to support multiple currencies, including USD, EUR, GBP, and INR.
    
    \textbf{Input/Condition}: Users perform transactions in each supported currency to verify correct processing.
    
    \textbf{Expected Result}: System successfully processes payment with all valid currencies

    \textbf{Result}: Test not completed

    \textbf{Comments}: Requirement is out of scope
    
    \item{T-OE4: Machine Learning Framework Compatibility Validation\\}
    
    
    \textbf{Initial State}: The system is configured with machine learning frameworks such as TensorFlow, PyTorch, and scikit-learn installed.
    
    \textbf{Input/Condition}: Users train and deploy models using each framework to verify compatibility.
    
    \textbf{Expected Result}: System successfully deploys models to each framework

    \textbf{Result}: Fail

    \textbf{Comments}: Not yet implemented
    
    \item{T-OE5: Data Pipeline Efficiency Validation\\}
    
    \textbf{Initial State}: The system has established data pipelines for transferring labeled datasets between the platform and ML models.
    
    \textbf{Input/Condition}: Large labeled datasets (e.g., 10,000 images) are transferred through the data pipelines.
    
    \textbf{Expected Result}: Data pipeline can support large datasets

    \textbf{Result}: Fail

    \textbf{Comments}: Not yet implemented
    
    
    
    \item{T-OE6: Web Browser Accessibility Validation\\}
    

    \textbf{Initial State}: Users have access to the platform's web URL.
    
    \textbf{Input/Condition}: Users attempt to access and use the platform via various supported web browsers without installing any software.
    
    \textbf{Expected Results}: Users are able to complete all key actions

    \textbf{Results}: Pass
    
    
    \item{T-OE7: Road Map Consistency\\}
                        
    \textbf{Initial State}: Application has a release road map that is publicly accessible.
                        
    \textbf{Input/Condition}: Team member conducts a review.
                        
    \textbf{Expected Results}: At least \hyperref[MIN_ON_TIME_MILESTONE]{MIN\_ON\_TIME\_MILESTONE}\% of the listed milestones have been met on time.
                        
    \textbf{Result}: Pass

    
    \item{Beta Testing: T-OE8\\}
    
                        
    \textbf{Initial State}: Beta version of application is deployed and accessible
                        
    \textbf{Input/Condition}: At least \hyperref[BETA_TESTERS]{BETA\_TESTERS} beta testers are provided access to use the application.
                        
    \textbf{Expected Results}: Feedback on any bugs, navigation issues, or aesthetic problems is provided. Less than \hyperref[MAX_BUGS_FOUND]{MAX\_BUGS\_FOUND} bugs are found.
                        
    \textbf{Result}: Pass

    \textbf{Comments}: Preliminary usability testing has been performed. See usability testing for details.
    
    \item{Regression Testing: T-OE9\\}
    
                        
    \textbf{Initial State}: Application is deployed.
                        
    \textbf{Input/Condition}: Run regression test suite, consisting of unit tests.
                        
    \textbf{Expected Results}: All regression tests are passed.
                        
    \textbf{Result}: Pass

    
    \end{enumerate}

\subsubsection{Analysis}
When conducting the validation of these requirements, we have identified a weakness of our current implementation. Of the seven attempted tests, only four passed. Of the ones that failed,
each one is due to a lack of focus from the development team. Now that there is a core structure in the application, we are able to begin addressing additional features, such as high performance data pipelines. 

\subsection{Maintainability and Support}
\subsubsection{Summary of Tests}
\begin{center}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{Test ID} & \textbf{Status} & \textbf{Notes}\\
        \hline
        T-MS0 & N/A & Test not yet attempted due to project being in early development.\\
        \hline
    \end{tabular}
\end{center}
\begin{enumerate}

\item{T-MS0: Ease of Change\\}

					
\textbf{Initial State}: Application's source repository contains complete documentation.
					
\textbf{Input/Condition}: Competent software developer who has not previously worked on the app reviews documentation and attempts to perform tasks.
					
\textbf{Expected Results}: The developer can easily make a minor update to a specified part of the application.
	
\textbf{Results}: Test not completed

\textbf{Comments}: Test not yet attempted due to project being in early development.
\end{enumerate}
\subsubsection{Analysis}
Although this test has not been attempted, the development team has been careful to write code that will be maintainable and match the design document description. This will ensure when this test is attempted, it will be successful.

\subsection{Security}
\subsubsection{Summary of Tests}
\begin{center}
    \begin{tabular}{|c|c|l|}
        \hline
        \textbf{Test ID} & \textbf{Status} & \textbf{Notes}\\
        \hline
        T-SE0 & Pass & \\
        T-SE1 & Pass & \\ 
        T-SE2 & Pass & \\ 
        T-SE3 & Pass & \\ 
        T-SE4 & Fail & Some passwords incorrectly fail\\ 
        T-SE5 & Pass & \\ 
        T-SE6 & Fail & Not yet implemented\\ 
        T-SE7 & Fail & Not yet implemented\\ 
        T-SE8 & N/A & Requirement is out of scope\\ 
        T-SE9 & Pass & \\ 
        \hline
    \end{tabular}
\end{center}


\begin{enumerate}

\item{T-SE0: Logged Out Permissions\\}
					
Initial State: Application is deployed.
					
Input/Condition: Tester who is not signed in tries to access application paths for project creation and image labeling (Ex. /projects or /label).
					
Output/Result: The tester is denied access to these paths and is told to sign in.
					
Result: Pass

\item{T-SE1: Labeler Permissions\\}

					
Initial State: Application is deployed.
					
Input/Condition: Tester who is signed in as a labeler tries to access application paths for project creation.
					
Output/Result: The tester is denied access to these paths. However, the tester has access to paths related to image labeling.
					
Result: Pass

\item{T-SE2: Invalid Email Format\\}

					
Initial State: Front-end registration page is created and integrated with the database.
					
Input/Condition: Email with invalid format, such as an empty string or a string missing '@', is entered.
					
Output/Result: Application rejects email and tells the user that the email format is wrong.
					
Result: Pass

\item{T-SE3: Duplicate Email\\}

					
Initial State: Front-end registration page is created and integrated with the database.
					
Input/Condition: Email that is already in database is entered.
					
Output/Result: Application rejects email and tells the user that the email is in use.
					
Result: Pass

\item{T-SE4: Invalid Password Format\\}

					
Initial State: Front-end registration page is created and integrated with the database.
					
Input/Condition: Password with invalid format, such as an empty string or a string with no numbers, is entered.
					
Output/Result: Application rejects password and tells the user what requirements they have not met.
					
Result: Fail

Comments: Some passwords which should pass, such as `Password123\#' fail.

\item{T-SE5: System Error\\}


					
Initial State: Application is deployed.
					
Input/Condition: Purposely invoke a system failure, and attempt to perform an action such as a label submission.
					
Output/Result: Application provides an error message on the user interface. The database has not changed in anyway.
					
Result: Pass



\item{T-SE6: Duplicate Entries\\}

					
Initial State: Database is deployed.
					
Input/Condition: Duplicate database entry is inserted into the database.
					
Output/Result: Database has only one of the inputted entry and the duplicate has been removed.
					
Result: Fail

Comments: Not yet implemented


\item{T-SE7: Encrypted User Data\\}

					
Initial State: Application is deployed.
					
Input/Condition: Tester registers an account.
					
Output/Result: All sensitive user data that is stored in the database is encrypted.
					
Result: Fail

Comments: Not yet implemented


\item{T-SE8: Encrypted Payments\\}

Type: Manual, Dynamic
					
Initial State: Application is deployed.
					
Input/Condition: Tester enters sample payment details to pay for a labeling project that has been created.
					
Output/Result: These details are encrypted and can not be read through packet analyzers. The amount in the request can not be modified by an adversary.
					
Result: Test not completed

Comments: Requirement is out of scope


\item{T-SE9: SQL Injection\\}

Type: Manual, Dynamic
					
Initial State: Application is deployed.
					
Input/Condition: A malicious SQL statement is entered into a text field.
					
Output/Result: The system raises an error telling the user that it is invalid.
					
Result: Pass

\end{enumerate}

\subsubsection{Analysis}
This application has been designed for security, and that is clear from the tests results. Six of the nine security tests pass, with partial passes for two of the failing tests. For the encryption test (T-SE7), user data is not yet encrypted, but passwords are. For the password validation test (T-SE4), 
all weak passwords are blocked, but some strong passwords are as well. The development team will address this issue in coming releases, but we are glad to know that if anything, we are not overly permissive. The requirement related to the remaining failed test (T-SE6), has been deemed `Medium' priority, and may be addressed in a future release.


\subsection{Cultural}
\subsection{Compliance}
\subsection{User Documentation and Training}


	
\section{Comparison to Existing Implementation}	

This section will not be appropriate for every project.

\section{Unit Testing}
\subsection{Front-end}
Please refer to the tests folder in the frontend directory found \href{https://github.com/OKKM-insights/frontend/tree/main/tests/__tests__}{here}.
\subsubsection{Rendering of a Component}
\begin{itemize}
    \item Description: A unit test was written for each component to ensure that it renders without error
    \item Inputs: The component
    \item Expected Outputs: The component renders 
    \item Result: Pass
\end{itemize}
\subsubsection{Open Pop Up}
\begin{itemize}
    \item Description: A unit test was written for each pop up component to ensure the pop up appears when open
    \item Inputs: open := true
    \item Expected Outputs: The pop up renders 
    \item Result: Pass
\end{itemize}
\subsubsection{Close Pop Up}
\begin{itemize}
    \item Description: A unit test was written for each pop up component to ensure the pop up does not appear when closed
    \item Inputs: open := false
    \item Expected Outputs: The pop up does not render 
    \item Result: Pass
\end{itemize}
\subsubsection{Header Logged In}
\begin{itemize}
    \item Description: Ensure the header renders the right things when the user is logged in
    \item Inputs: logged in := true
    \item Expected Outputs: The header should contain the log out button and profile button
    \item Result: Pass
\end{itemize}
\subsubsection{Header Logged Out}
\begin{itemize}
    \item Description: Ensure the header renders the right things when the user is logged out
    \item Inputs: logged in := false
    \item Expected Outputs: The header should contain the log in button and register button
    \item Result: Pass
\end{itemize}
\subsubsection{Header Re-directions}
\begin{itemize}
    \item Description: Ensure the headers buttons redirect to the expected link
    \item Inputs: N/A
    \item Expected Outputs: The header redirects to the login on pressing the login button, register on pressing the register button, home when clicking the logout button, and edit profile information when clicking the profile button 
    \item Result: Pass
\end{itemize}
\subsubsection{Login Success}
\begin{itemize}
    \item Description: Ensure the authorization context is set up upon successful login
    \item Inputs: valid email and password
    \item Expected Outputs: Login is successful and authorization context is set up
    \item Result: Pass
\end{itemize}
\subsubsection{Login Fail}
\begin{itemize}
    \item Description: Ensure error message is displayed on login fail
    \item Inputs: invalid email and password
    \item Expected Outputs: Message saying invalid credentials
    \item Result: Pass
\end{itemize}
\subsubsection{New Project Validation}
\begin{itemize}
    \item Description: Ensure required inputs are filled and notify the user if not
    \item Inputs: empty required fields such as name
    \item Expected Outputs: Message saying what required fields have not been filled in
    \item Result: Pass
\end{itemize}
\subsubsection{New Project Creation Success}
\begin{itemize}
    \item Description: Ensure form submission occurs and success pop up is activated when server creates project
    \item Inputs: Entirely filled out project creation form
    \item Expected Outputs: Success pop up shown
    \item Result: Pass
\end{itemize}
\subsubsection{New Project Creation Failure}
\begin{itemize}
    \item Description: Ensure form submission occurs and failure pop up is activated when a server side error occurs
    \item Inputs: Entirely filled out project creation form
    \item Expected Outputs: Failure pop up shown
    \item Result: Pass
\end{itemize}
\subsubsection{Project Section renders all projects}
\begin{itemize}
    \item Description: Ensure projects section component renders all projects given to it
    \item Inputs: A list of projects
    \item Expected Outputs: Each project has its own project card on the page
    \item Result: Pass
\end{itemize}
\subsubsection{Project Tile Navigation}
\begin{itemize}
    \item Description: Ensure project tile redirects to the correct page
    \item Inputs: tile type
    \item Expected Outputs: When the tile type is label, it redirects to the label project. When the tile type is client, it redirects to project insights.
    \item Result: Pass
\end{itemize}
\subsubsection{Register Dynamic Password Validation}
\begin{itemize}
    \item Description: Ensure the password conditions show as satisfied when given a valid password
    \item Inputs: A valid password
    \item Expected Outputs: Password conditions show as satisfied
    \item Result: Pass
\end{itemize}
\subsubsection{Register Success}
\begin{itemize}
    \item Description: Ensure the form is submitted, shows a success pop up, and redirect
    \item Inputs: valid email and password
    \item Expected Outputs: Success pop up comes up and redirected to the login page
    \item Result: Pass
\end{itemize}
\subsubsection{Register Fail}
\begin{itemize}
    \item Description: Ensure the user is notified if the account already exists
    \item Inputs: duplicate email
    \item Expected Outputs: Message saying the account already exists
    \item Result: Pass
\end{itemize}
\subsubsection{Update Info Success}
\begin{itemize}
    \item Description: Ensure the form is submitted and the new information is now displayed
    \item Inputs: valid email change
    \item Expected Outputs: Email on the account information page is updated to the new email
    \item Result: Pass
\end{itemize}
\subsubsection{Update Info Fail}
\begin{itemize}
    \item Description: Ensure the user is notified if the account already exists, do not allow update
    \item Inputs: duplicate email
    \item Expected Outputs: Message saying the account already exists
    \item Result: Pass
\end{itemize}

\section{Changes Due to Testing}

\wss{This section should highlight how feedback from the users and from 
the supervisor (when one exists) shaped the final product.  In particular 
the feedback from the Rev 0 demo to the supervisor (or to potential users) 
should be highlighted.}

\subsection{Changes to Front-end}
Our labeling tool was largely refactored to incorporate the feedback we received from our usability testing. We also considered some of the unit testing outcomes. These changes included:
\begin{itemize}
    \item Added clearer visual feedback to all the buttons present in the labeling tool. Also made the currently selected label type more obvious to the user.
    \item Changed the contextual pop ups to include more detailed descriptions and any short cuts associated with a button.
    \item Added more details and made steps more granular in the help walk-through of the labeling tool. These additional details should help the user in further understanding what they need to do.
    \item Changed the text of the main submission buttons so that it was clear what would happen when they were pressed. For example, submit was renamed to "submit labels".
    \item Fixed a bug where the tool would get stuck if the submit button was pushed when there was no labels made.
    \item The label button now stays selected after a label is created so the user can seamlessly label multiple objects of the same class without having to reselect it every time.
    \item A visual gif will be added to show the basic process of creating a label so that it is clear the labels are to be drawn on the image.
    \item Rather than have tools spread out, they have all been condensed into an easy access toolbar.
    \item New button was added to reset zoom, contrast, brightness and image position back to its initial state.
    \item Removed white space.
    \item Removed help button when the project was complete.
\end{itemize}

\section{Automated Testing}
		
\section{Trace to Requirements}
The traceability from tests to requirements can be seen in section 4.3 of the \href{https://github.com/OKKM-insights/OKKM.insights/blob/main/docs/VnVPlan/VnVPlan.pdf}{VnV Plan}.
		
\section{Trace to Modules}
The traceability from requirements to modules can be seen in section 8 of the \href{https://github.com/OKKM-insights/OKKM.insights/blob/main/docs/Design/SoftArchitecture/MG.pdf}{Module Guide}. The tests that cover a specific requirement also cover the modules associated with that requirement.	

\section{Code Coverage Metrics}
\subsection{Front-end Coverage}
The coverage results of the front-end unit testing can be seen in Figure~\ref{fig:FE_coverage}. Perfect coverage was not achieved, but we believe our unit tests supplemented with our manual and usability tests provide sufficient coverage of the code.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{FE_coverage.png}
    \caption{Front-end Unit Testing Coverage Results}
    \label{fig:FE_coverage}
\end{figure}

\bibliographystyle{plainnat}
\bibliography{../../refs/References}

\newpage{}
\section*{Appendix --- Reflection}

The information in this section will be used to evaluate the team members on the
graduate attribute of Reflection.

\input{../Reflection.tex}

\begin{enumerate}
  \item What went well while writing this deliverable? 
  \item What pain points did you experience during this deliverable, and how
    did you resolve them?
  \item Which parts of this document stemmed from speaking to your client(s) or
  a proxy (e.g. your peers)? Which ones were not, and why?
  \item In what ways was the Verification and Validation (VnV) Plan different
  from the activities that were actually conducted for VnV?  If there were
  differences, what changes required the modification in the plan?  Why did
  these changes occur?  Would you be able to anticipate these changes in future
  projects?  If there weren't any differences, how was your team able to clearly
  predict a feasible amount of effort and the right tasks needed to build the
  evidence that demonstrates the required quality?  (It is expected that most
  teams will have had to deviate from their original VnV Plan.)
\end{enumerate}

\end{document}
